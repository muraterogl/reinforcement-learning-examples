{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7AUmdU8G55Q6HdZbjUAcT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiErnjsiQEwO"
      },
      "outputs": [],
      "source": [
        "# https://ymd_h.gitlab.io/ymd_blog/posts/gym_on_google_colab_with_gnwrapper/\n",
        "# https://www.youtube.com/watch?v=dWmJ5CXSKdw\n",
        "!apt update > /dev/null 2>&1\n",
        "!apt install xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install --upgrade pip wheel==0.38.4 setuptools==65.5.1\n",
        "!pip install gym==0.25.1 gym_super_mario_bros==7.3.0 nes_py==8.2.1 gym-notebook-wrapper==1.3.3 > /dev/null 2>&1\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 > /dev/null 2>&1\n",
        "# Install stable baselines for RL stuff\n",
        "!pip install stable-baselines3[extra]==1.8.0 > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "import gnwrapper"
      ],
      "metadata": {
        "id": "P46dBfbj5ah_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "env = gnwrapper.Monitor(env, directory=\"./\")"
      ],
      "metadata": {
        "id": "v6DZqUOt7IsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done = True\n",
        "for step in range(1000):\n",
        "    if done:\n",
        "        env.reset()\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "env.display()\n",
        "env.close()"
      ],
      "metadata": {
        "id": "Y2Cn6nYd7RRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the environment"
      ],
      "metadata": {
        "id": "uxNgX2boFvGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Frane Stacker Wrapper and GrayScaling Wrapper\n",
        "from gym.wrappers import GrayScaleObservation\n",
        "# Import Vectorization Wrappers\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "# Import Matplotlib to show the impact of frame stacking\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4Kb422sJFyPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the base environment\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "# 2. Simplify the controls\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "# 3. Grayscale\n",
        "env = GrayScaleObservation(env, keep_dim=True)\n",
        "# 4. Wrap inside the Dummy Environment\n",
        "env = DummyVecEnv([lambda: env])\n",
        "# 5. Stack the frames\n",
        "env = VecFrameStack(env, 4, channels_order='last')\n",
        "state = env.reset()\n",
        "print(state.shape)\n",
        "plt.imshow(state[0])\n",
        "# 6. Wrap it for the colab monitor\n",
        "# env = gnwrapper.Monitor(env, directory=\"./\")"
      ],
      "metadata": {
        "id": "YZlkz_-SKNXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the RL Model"
      ],
      "metadata": {
        "id": "hjEAD7GpdCyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M_ws9J2tc5t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os for file path management\n",
        "import os\n",
        "# Import PPO for algos\n",
        "from stable_baselines3 import PPO\n",
        "# Import Base Callback for saving models\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "lKoh3TpzdFPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq, start_freq, save_path, verbose=1):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.start_freq = start_freq\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def _init_callback(self):\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = os.path.join(self.save_path, f'mario_model_{self.n_calls+self.start_freq}')\n",
        "            self.model.save(model_path)\n",
        "        return True\n",
        "\n",
        "DRIVE_DIR = './drive/My Drive/Projects/reinforcement-learning-examples/'\n",
        "CHECKPOINT_DIR = os.path.join(DRIVE_DIR, 'train/')\n",
        "LOG_DIR = os.path.join(DRIVE_DIR, 'logs/')\n",
        "# Setup model saving callback\n",
        "callback = TrainAndLoggingCallback(check_freq=10000, start_freq=0, save_path=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "0hJKr9fxdmG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the AI model started\n",
        "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, n_steps=512)"
      ],
      "metadata": {
        "id": "0BM0b_x6f6kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the AI model, this is where the AI model starts to learn\n",
        "model.learn(total_timesteps=10000, callback=callback)"
      ],
      "metadata": {
        "id": "-JJioH46iEvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test it Out"
      ],
      "metadata": {
        "id": "WR4b11y_mThe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO.load(os.path.join(CHECKPOINT_DIR, 'mario_model_10000'))"
      ],
      "metadata": {
        "id": "12N1VXXPmWPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gnwrapper.Monitor(env, directory=\"./\")\n",
        "state = env.reset()\n",
        "\n",
        "for _ in range(10000):\n",
        "    action, _ = model.predict(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "env.display()\n",
        "env.close()"
      ],
      "metadata": {
        "id": "6o9c-XqRmb-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}